{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12745533,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader,Dataset\nimport os\nimport pandas\nimport numpy\nfrom torchvision  import transforms,datasets\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification\nfrom torch.utils.data import random_split\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T17:57:47.493468Z","iopub.execute_input":"2025-09-23T17:57:47.493742Z","iopub.status.idle":"2025-09-23T17:57:47.497906Z","shell.execute_reply.started":"2025-09-23T17:57:47.493724Z","shell.execute_reply":"2025-09-23T17:57:47.497263Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T17:57:47.695838Z","iopub.execute_input":"2025-09-23T17:57:47.696435Z","iopub.status.idle":"2025-09-23T17:57:47.701436Z","shell.execute_reply.started":"2025-09-23T17:57:47.696393Z","shell.execute_reply":"2025-09-23T17:57:47.700805Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Transforms","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n   transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:53.799522Z","iopub.execute_input":"2025-09-23T18:12:53.800266Z","iopub.status.idle":"2025-09-23T18:12:53.804914Z","shell.execute_reply.started":"2025-09-23T18:12:53.800242Z","shell.execute_reply":"2025-09-23T18:12:53.804320Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## DataSep","metadata":{}},{"cell_type":"code","source":"test=datasets.ImageFolder(root=\"/kaggle/input/brain-tumor-classification-mri/Testing\",transform=test_transform)\ntrain=datasets.ImageFolder(root=\"/kaggle/input/brain-tumor-classification-mri/Training\",transform=train_transform)\ntrain_size = int(0.8 * len(train))\nval_size = len(train) - train_size\n\ntrain_dataset, val_dataset = random_split(train, [train_size, val_size])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:55.205349Z","iopub.execute_input":"2025-09-23T18:12:55.205638Z","iopub.status.idle":"2025-09-23T18:12:58.604486Z","shell.execute_reply.started":"2025-09-23T18:12:55.205619Z","shell.execute_reply":"2025-09-23T18:12:58.603915Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True)\nval_loader=DataLoader(val_dataset,batch_size=16,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:58.605533Z","iopub.execute_input":"2025-09-23T18:12:58.605745Z","iopub.status.idle":"2025-09-23T18:12:58.609903Z","shell.execute_reply.started":"2025-09-23T18:12:58.605721Z","shell.execute_reply":"2025-09-23T18:12:58.609261Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"test_loader=DataLoader(test,batch_size=16,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:58.610679Z","iopub.execute_input":"2025-09-23T18:12:58.610939Z","iopub.status.idle":"2025-09-23T18:12:58.623532Z","shell.execute_reply.started":"2025-09-23T18:12:58.610918Z","shell.execute_reply":"2025-09-23T18:12:58.622842Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\nmodel = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n\nnum_classes = len(train.classes)  #here is it 4\nprint(f\"Number of classes in dataset: {num_classes}\")\nprint(f\"Classes: {train.classes}\")\n#we adjust classifier head \nmodel.classifier = torch.nn.Linear(model.config.hidden_size, num_classes)\n\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:58.624828Z","iopub.execute_input":"2025-09-23T18:12:58.625290Z","iopub.status.idle":"2025-09-23T18:12:59.342867Z","shell.execute_reply.started":"2025-09-23T18:12:58.625272Z","shell.execute_reply":"2025-09-23T18:12:59.342091Z"}},"outputs":[{"name":"stderr","text":"Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n","output_type":"stream"},{"name":"stdout","text":"Number of classes in dataset: 4\nClasses: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"ViTForImageClassification(\n  (vit): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  )\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"loss_function = torch.nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:12:59.472665Z","iopub.execute_input":"2025-09-23T18:12:59.473029Z","iopub.status.idle":"2025-09-23T18:12:59.477129Z","shell.execute_reply.started":"2025-09-23T18:12:59.473007Z","shell.execute_reply":"2025-09-23T18:12:59.476427Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"\"\"\"class ViTProcessorTransform:   #you can do this or just make sure the transofrms are exactly vits correct ones in the transforms\n    def __init__(self, processor):\n        self.processor = processor\n    \n    def __call__(self, image):\n        # Convert PIL to RGB if needed\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n        \n        # Use ViT processor\n        processed = self.processor(image, return_tensors=\"pt\")\n        return processed['pixel_values'].squeeze(0)\ntransform = transforms.Compose([\n    ViTProcessorTransform(processor),\n    #+ the augmentations stuff for train transofmrs\n])\"\"\"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:14:10.930442Z","iopub.execute_input":"2025-09-23T18:14:10.930711Z","iopub.status.idle":"2025-09-23T18:14:10.937094Z","shell.execute_reply.started":"2025-09-23T18:14:10.930692Z","shell.execute_reply":"2025-09-23T18:14:10.936416Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"train_N = len(train_loader.dataset)\ntest_N = len(test_loader.dataset)\nprint(train_N,test_N)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:14:12.397634Z","iopub.execute_input":"2025-09-23T18:14:12.398112Z","iopub.status.idle":"2025-09-23T18:14:12.402532Z","shell.execute_reply.started":"2025-09-23T18:14:12.398090Z","shell.execute_reply":"2025-09-23T18:14:12.401838Z"}},"outputs":[{"name":"stdout","text":"2296 394\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"epochs = 10\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1}/{epochs}\")\n    \n    # training \n    train_loss = 0\n    train_correct = 0\n    model.train()\n    \n    for batch_idx, (x, y) in enumerate(train_loader):\n        x, y = x.to(device), y.to(device)\n        \n        output = model(x)\n        logits = output.logits\n        \n        optimizer.zero_grad()\n        batch_loss = loss_function(logits, y)\n        \n        batch_loss.backward()\n        optimizer.step()\n        \n        train_loss += batch_loss.item()\n        train_correct += (logits.argmax(dim=1) == y).sum().item()\n        \n        if batch_idx % 20 == 0:  # we can just write the progres each 20 batch in the epoch\n            print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {batch_loss.item():.4f}')\n    \n    train_accuracy = train_correct / len(train_loader.dataset)\n    avg_train_loss = train_loss / len(train_loader)\n    print(f'Train - Loss: {avg_train_loss:.4f} Accuracy: {train_accuracy:.4f}')\n    \n    # validation \n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    \n    with torch.no_grad():\n        for x, y in val_loader:  \n            x, y = x.to(device), y.to(device)\n            output = model(x)\n            logits = output.logits\n            \n            val_loss += loss_function(logits, y).item()\n            val_correct += (logits.argmax(dim=1) == y).sum().item()\n    \n    val_accuracy = val_correct / len(val_loader.dataset)\n    avg_val_loss = val_loss / len(val_loader)\n    print(f'Valid - Loss: {avg_val_loss:.4f} Accuracy: {val_accuracy:.4f}')\n    print('-' * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:14:12.627053Z","iopub.execute_input":"2025-09-23T18:14:12.627663Z","iopub.status.idle":"2025-09-23T18:24:30.162733Z","shell.execute_reply.started":"2025-09-23T18:14:12.627640Z","shell.execute_reply":"2025-09-23T18:24:30.161818Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nBatch 0/144, Loss: 1.4370\nBatch 20/144, Loss: 0.9229\nBatch 40/144, Loss: 0.3206\nBatch 60/144, Loss: 0.4727\nBatch 80/144, Loss: 0.1109\nBatch 100/144, Loss: 0.5192\nBatch 120/144, Loss: 0.0288\nBatch 140/144, Loss: 0.0698\nTrain - Loss: 0.4051 Accuracy: 0.8432\nValid - Loss: 0.1897 Accuracy: 0.9425\n--------------------------------------------------\nEpoch 2/10\nBatch 0/144, Loss: 0.0055\nBatch 20/144, Loss: 0.0560\nBatch 40/144, Loss: 0.0037\nBatch 60/144, Loss: 0.0140\nBatch 80/144, Loss: 0.0242\nBatch 100/144, Loss: 0.0034\nBatch 120/144, Loss: 0.0885\nBatch 140/144, Loss: 0.0373\nTrain - Loss: 0.0920 Accuracy: 0.9695\nValid - Loss: 0.2224 Accuracy: 0.9408\n--------------------------------------------------\nEpoch 3/10\nBatch 0/144, Loss: 0.1405\nBatch 20/144, Loss: 0.0459\nBatch 40/144, Loss: 0.0275\nBatch 60/144, Loss: 0.0031\nBatch 80/144, Loss: 0.0503\nBatch 100/144, Loss: 0.1181\nBatch 120/144, Loss: 0.0289\nBatch 140/144, Loss: 0.0011\nTrain - Loss: 0.0474 Accuracy: 0.9856\nValid - Loss: 0.1711 Accuracy: 0.9460\n--------------------------------------------------\nEpoch 4/10\nBatch 0/144, Loss: 0.0039\nBatch 20/144, Loss: 0.0022\nBatch 40/144, Loss: 0.0018\nBatch 60/144, Loss: 0.1885\nBatch 80/144, Loss: 0.0307\nBatch 100/144, Loss: 0.0072\nBatch 120/144, Loss: 0.0010\nBatch 140/144, Loss: 0.0122\nTrain - Loss: 0.0429 Accuracy: 0.9878\nValid - Loss: 0.2144 Accuracy: 0.9408\n--------------------------------------------------\nEpoch 5/10\nBatch 0/144, Loss: 0.0045\nBatch 20/144, Loss: 0.0006\nBatch 40/144, Loss: 0.0006\nBatch 60/144, Loss: 0.0004\nBatch 80/144, Loss: 0.0047\nBatch 100/144, Loss: 0.0040\nBatch 120/144, Loss: 0.2339\nBatch 140/144, Loss: 0.0142\nTrain - Loss: 0.0348 Accuracy: 0.9891\nValid - Loss: 0.0843 Accuracy: 0.9791\n--------------------------------------------------\nEpoch 6/10\nBatch 0/144, Loss: 0.0003\nBatch 20/144, Loss: 0.0005\nBatch 40/144, Loss: 0.0010\nBatch 60/144, Loss: 0.0005\nBatch 80/144, Loss: 0.0019\nBatch 100/144, Loss: 0.0006\nBatch 120/144, Loss: 0.0012\nBatch 140/144, Loss: 0.0088\nTrain - Loss: 0.0129 Accuracy: 0.9961\nValid - Loss: 0.1195 Accuracy: 0.9652\n--------------------------------------------------\nEpoch 7/10\nBatch 0/144, Loss: 0.0011\nBatch 20/144, Loss: 0.0010\nBatch 40/144, Loss: 0.0005\nBatch 60/144, Loss: 0.0362\nBatch 80/144, Loss: 0.0410\nBatch 100/144, Loss: 0.0112\nBatch 120/144, Loss: 0.0466\nBatch 140/144, Loss: 0.0109\nTrain - Loss: 0.0511 Accuracy: 0.9821\nValid - Loss: 0.1395 Accuracy: 0.9564\n--------------------------------------------------\nEpoch 8/10\nBatch 0/144, Loss: 0.0046\nBatch 20/144, Loss: 0.0139\nBatch 40/144, Loss: 0.0251\nBatch 60/144, Loss: 0.0023\nBatch 80/144, Loss: 0.0025\nBatch 100/144, Loss: 0.0009\nBatch 120/144, Loss: 0.0023\nBatch 140/144, Loss: 0.0396\nTrain - Loss: 0.0171 Accuracy: 0.9956\nValid - Loss: 0.1670 Accuracy: 0.9582\n--------------------------------------------------\nEpoch 9/10\nBatch 0/144, Loss: 0.0029\nBatch 20/144, Loss: 0.0032\nBatch 40/144, Loss: 0.0022\nBatch 60/144, Loss: 0.0023\nBatch 80/144, Loss: 0.0178\nBatch 100/144, Loss: 0.0013\nBatch 120/144, Loss: 0.0004\nBatch 140/144, Loss: 0.0007\nTrain - Loss: 0.0188 Accuracy: 0.9952\nValid - Loss: 0.1528 Accuracy: 0.9652\n--------------------------------------------------\nEpoch 10/10\nBatch 0/144, Loss: 0.0007\nBatch 20/144, Loss: 0.0008\nBatch 40/144, Loss: 0.0362\nBatch 60/144, Loss: 0.0561\nBatch 80/144, Loss: 0.0004\nBatch 100/144, Loss: 0.0158\nBatch 120/144, Loss: 0.0634\nBatch 140/144, Loss: 0.0747\nTrain - Loss: 0.0436 Accuracy: 0.9839\nValid - Loss: 0.2120 Accuracy: 0.9373\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\n# Collect all predictions and true labels\nall_predictions = []\nall_true_labels = []\n\n\nmodel.eval()\nwith torch.no_grad():\n        for x, y in test_loader:\n            x, y = x.to(device), y.to(device)\n            output = model(x)\n            logits = output.logits\n            predictions = logits.argmax(dim=1)\n\n            all_predictions.extend(predictions.cpu().numpy())\n            all_true_labels.extend(y.cpu().numpy())\nclass_names = test_loader.dataset.classes  # Assuming your dataset has class names\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(all_true_labels, all_predictions, \n                          target_names=class_names, digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T18:24:30.164107Z","iopub.execute_input":"2025-09-23T18:24:30.164602Z","iopub.status.idle":"2025-09-23T18:24:34.828812Z","shell.execute_reply.started":"2025-09-23T18:24:30.164581Z","shell.execute_reply":"2025-09-23T18:24:34.828058Z"}},"outputs":[{"name":"stdout","text":"\nDetailed Classification Report:\n                  precision    recall  f1-score   support\n\n    glioma_tumor     1.0000    0.2100    0.3471       100\nmeningioma_tumor     0.7737    0.9217    0.8413       115\n        no_tumor     0.5909    0.9905    0.7402       105\n pituitary_tumor     0.9500    0.7703    0.8507        74\n\n        accuracy                         0.7310       394\n       macro avg     0.8287    0.7231    0.6948       394\n    weighted avg     0.8155    0.7310    0.6907       394\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"### Bad bad for the glioma so i will try to adjust the class weights","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}